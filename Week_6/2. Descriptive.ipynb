{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Descriptive..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The outliers....\n",
    "\n",
    "![title](Outlier.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outlier has a value that is far from the bulk of the data (can go on either direction).\n",
    "\n",
    "These outliers are highly damaging as they can drive a particular analysis one way or the other\n",
    "\n",
    "![title](bad_outlier.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Multivariate analysis such as PCA (which we will cover soon) outliers tend to dominate the first main components, thus in some circumstances driving opposite conclusions.\n",
    "\n",
    "However, outliers can have a substantial analytical model, it can point to interesting behaviors of the data, be of biological relevance or illustrate relevant flaws with a particular design. \n",
    "\n",
    "### !!!Do Not Remove Outliers Before Investigating What do they Represent!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to detect outliers!!\n",
    "Graphical means of detecting outliers work the best, let's look at boxplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots\n",
    "\n",
    "The boxplot identifies the center of the data (median) and the spread (either variance or standard deviation or the 25% - 75% quartiles. beyond the box usually statistical software draw a line going up and down from the center of the box, these represent 1.5 times the spread. Points or circles beyond these lines represent observations that occur past all these spread measurements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at an example.\n",
    "\n",
    "This dataset was used on a study conducted by Cruikshanks et al 2006, the main goal was to identify acid-sensitive water in coastal rives in Ireland. Using pH as a function of SDI (Sodium Dominance Index), the altitude of the site and the presence of absence of forest. Let's look at the boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrishpH <- read.table(file = \"IrishpH.txt\",\n",
    "                      header = TRUE,\n",
    "                      dec = \".\")\n",
    "library(car)\n",
    "par(mar = c(5,5,2,2), cex.lab = 1.5)\n",
    "Boxplot(IrishpH$Altitude, ylab = \"Altitude\")\n",
    "stripchart(IrishpH$Altitude, \n",
    "           vertical = TRUE, method = \"jitter\", \n",
    "           pch = 21,add = TRUE,col=rgb(1, 0, 0,0.5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(mosaic)\n",
    "favstats(IrishpH$Altitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also should look at all of the variables in our model which will be part of the analysis, to have a good idea of how they will behave. Let’s use another data set, in this case we will use  data use by Ligas (2008). In their study they look at the effect of month and sex on cephalothorax length of the red swamp crayfish *Procambarus clarkii*. They use multiple variables to test their model (weight, sex, month, and sexual maturity of 746 crayfish individuals).\n",
    "\n",
    "We can construct a **conditional boxplot** that evaluates the change of thorax length at different months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crayfish <- read.table(file = \"Procambarus.txt\",\n",
    "                         header = TRUE,\n",
    "                         dec = \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Crayfish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install.packages(\"car\")\n",
    "library(car)\n",
    "Boxplot(CTL ~ Month,\n",
    "        ylab = \"Cephalothorax Length\",\n",
    "        xlab = \"Month\", \n",
    "        data= Crayfish,\n",
    "        main = expression(italic(\"Procambarus clarkii\")))\n",
    "\n",
    "stripchart(CTL ~ Month,data = Crayfish, \n",
    "           vertical = TRUE, method = \"jitter\", \n",
    "           pch = 21, \n",
    "           add = TRUE,col=rgb(1, 0, 0,0.5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let’s stop for a moment here and review an important extra piece of information that these boxplots also gives us. \n",
    "\n",
    "When we are comparing multiple variables in a parametric statistical test (where normality is assumed), one of the main conditions to be able to compare across variables is that there is **homogeneity of variance (called homoscedasticity)**. This happens when the spread of all values of the population is the same for every value of the covariate. \n",
    "\n",
    "For example: looking at the Crayfish conditional box plot, we see that most of the classes of our variable have a similar patterns of spread, except for the second class (Mar_05) where the variance is much smaller and seems skewed. One quick read to the points spread seems to illustrate that there is low sampling that can be skewing the distribution.\n",
    "\n",
    "There are multiple statistical tests that allows us to test for homogeneity of variances, such as the Bartlett test, the F-ratio test, and the Levene’s test among others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another useful visualization technique is the violin plot. It is similar to a box plot with a rotated kernel density plot.\n",
    "\n",
    "Continuing with the Irish water quality dataset, lets construct violong plots to the same data we evaluated before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "ggplot(data = Crayfish, aes(x = Month, y = CTL)) +\n",
    "  geom_boxplot(alpha = 0.2) +\n",
    "  geom_violin(fill='red', color='red',  alpha=0.4) +\n",
    "  geom_jitter(alpha = 0.6, color = \"black\") + \n",
    "  theme_bw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note here that there are a lot of missing values. Missing values can also have an effect on the behavior of the data and to our results.\n",
    "\n",
    "We need to understand if the missing values that we have have a biological basis, an artifact of the sampling, or simply clerical errors.\n",
    "\n",
    "We can count the number of missing values with the function is.na in R.\n",
    "\n",
    "How can we deal with zeros in the data??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(Crayfish$CTL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleveland dotplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting way of looking at the data is using dotplots, which basically we plot the row number of an observation vs the observed value, the y-axis shows how the data is ordered and the x-axis shows the values.\n",
    "\n",
    "Let’s look at the Irish pH dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mar = c(5,5,2,2), cex.lab = 1.5, cex.main = 1.5)\n",
    "dotchart(IrishpH$Altitude,\n",
    "         main = \"Altitude\",\n",
    "         ylab = \"Order of the data\",\n",
    "         xlab = \"Range of the data\")\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(IrishpH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(IrishpH, aes(ID,Altitude)) +\n",
    "  geom_point(stat = \"identity\") +\n",
    "  geom_text(data=subset(IrishpH, Altitude > 400),\n",
    "            aes(ID,Altitude,label=Altitude),hjust = -0.2)+\n",
    "  coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to do if you suspect that there are outliers in your data?\n",
    "\n",
    "1. If you are sure they are outliers, remove them\n",
    "2. Run the models with and without the outliers, present this data with analysis.\n",
    "3. Apply a transformation\n",
    "\n",
    "### Transformations\n",
    "\n",
    "Transformations change the dispersion of the data. As the transformation is applied to all elements from the data, there is no problem with biasing the data. \n",
    "\n",
    "There are multiple types of transformation (see here for a complete review [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3043340/](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3043340/)\n",
    "The three most used are logarithmic, square root, and reciprocal.\n",
    "\n",
    "We can check the example from the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimodalData_s = read.csv(file = \"plant_heights.csv\",header = T)\n",
    "\n",
    "bimodalData_s$log = log(bimodalData_s$x)\n",
    "bimodalData_s$log10 = log(bimodalData_s$x,10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = runif(1000)\n",
    "plot(a)\n",
    "hist(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(bimodalData_s$x,seq(1:10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d= density(bimodalData_s$x)\n",
    "par(mfrow = c(1,2))\n",
    "plot(d)\n",
    "\n",
    "qqnorm(bimodalData_s$x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(bimodalData_s$log10,seq(1:10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Histograms\n",
    "\n",
    "As we have seen previously, histograms are useful when we want to check for normality (which is important if we want to apply some statistical tests). The histogram aims to show the center and distribution of the data\n",
    "\n",
    "To create an histogram we first create a frequency table,\n",
    "par(mfrow = c(1,3))\n",
    "hist(bimodalData_s$log)\n",
    "\n",
    "d= density(bimodalData_s$log10)\n",
    "plot(d)\n",
    "\n",
    "qqnorm(log(bimodalData_s$x,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = round(rnorm(1000,0,1),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets run another example let's run the dataset sparrows and select one species\n",
    "##lets plot the histogram of weights\n",
    "\n",
    "Sparrows = read.table(file = \"Sparrows.txt\", header = TRUE)\n",
    "Sparrows2 = Sparrows[Sparrows$Species == \"SSTS\",]\n",
    "hist(Sparrows2$Wt, xlab = \"Weight in grams\", main = expression(italic(\"Ammodramus caudacutus\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also draw multiple histograms using the lattice package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sparrows2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(lattice)\n",
    "histogram(~Wt|factor(Observer),\n",
    "         data = Sparrows2,\n",
    "         layout = c(1,7),\n",
    "         nint = 30,\n",
    "         xlab = \"Weight in grams\",\n",
    "         strip = FALSE,\n",
    "         strip.left = TRUE,\n",
    "         ylab = \"Frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going back to our initial example we can change the size of the bins to make it more define as a continuous distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(x, breaks = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(x, breaks = 400) ##but we loose resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### However, with this shape, it is still a little difficult to assess whether the raw data follows a normal distribution. Ir order to solve this problem we can use Kernel Density Curves and qqplots that we already reviewed in previous classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
